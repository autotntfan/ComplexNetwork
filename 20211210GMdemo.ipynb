{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "411630c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import complexnn\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Layer\n",
    "import keras\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "np.random.default_rng(7414)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4095ce",
   "metadata": {},
   "source": [
    "# Inception Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0126d4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptLayer(Layer):\n",
    "    def __init__(self,\n",
    "                 filter1,\n",
    "                 filter2,\n",
    "                 filter3,\n",
    "                 filter4,\n",
    "                 kernel1,\n",
    "                 kernel2,\n",
    "                 kernel3,\n",
    "                 kernel4,\n",
    "                 num_units=4,\n",
    "                 name='InceptionLayer',**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.filter1 = filter1\n",
    "        self.filter2 = filter2\n",
    "        self.filter3 = filter3\n",
    "        self.filter4 = filter4\n",
    "        self.kernel1 = kernel1\n",
    "        self.kernel2 = kernel2\n",
    "        self.kernel3 = kernel3\n",
    "        self.kernel4 = kernel4\n",
    "        self.num_units = num_units\n",
    "    def build(self, input_shape):\n",
    "        self.conv1 = complexnn.conv.ComplexConv2D(self.filter1,self.kernel1,padding='same')\n",
    "        self.conv2 = complexnn.conv.ComplexConv2D(self.filter2,self.kernel2,padding='same')\n",
    "        self.conv3 = complexnn.conv.ComplexConv2D(self.filter3,self.kernel3,padding='same')\n",
    "        self.conv4 = complexnn.conv.ComplexConv2D(self.filter4,self.kernel4,padding='same')\n",
    "        self.act = AmplitudeMaxout_inclued(self.num_units)\n",
    "    def call(self, x):\n",
    "        conv_output1 = self.conv1(x)\n",
    "        real1, imag1 = self.seperate(self.act(conv_output1))\n",
    "        conv_output2 = self.conv2(x)\n",
    "        real2, imag2 = self.seperate(self.act(conv_output2))\n",
    "        conv_output3 = self.conv3(x)\n",
    "        real3, imag3 = self.seperate(self.act(conv_output3))\n",
    "        conv_output4 = self.conv4(x)\n",
    "        real4, imag4 = self.seperate(self.act(conv_output4))\n",
    "        return tf.concat([real1,real2,real3,real4,imag1,imag2,imag3,imag4], axis=-1)\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        last_dim1 = self.compute_shape(self.filter1,self.num_units,self.filter1%self.num_units)\n",
    "        last_dim2 = self.compute_shape(self.filter2,self.num_units,self.filter2%self.num_units)\n",
    "        last_dim3 = self.compute_shape(self.filter3,self.num_units,self.filter3%self.num_units)\n",
    "        last_dim4 = self.compute_shape(self.filter4,self.num_units,self.filter4%self.num_units)\n",
    "        shape = list(input_shape)\n",
    "        shape[-1] = last_dim1 + last_dim2 + last_dim3 + last_dim4\n",
    "        return tuple(shape)\n",
    "    \n",
    "    def get_config(self):\n",
    "        pass\n",
    "    \n",
    "    def seperate(self, x):\n",
    "        shape = x.get_shape().as_list()\n",
    "        dim = shape[-1]//2\n",
    "        realpart = x[:,:,:,:dim]\n",
    "        imagpart = x[:,:,:,dim:]\n",
    "        return realpart, imagpart\n",
    "    def compute_shape(self,filters,units,flag):\n",
    "        if flag:\n",
    "            return 2*(filters//units + 1)\n",
    "        else:\n",
    "            return 2*(filters//units)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c31bd1",
   "metadata": {},
   "source": [
    "# Activation function:AMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a85b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmplitudeMaxout(Layer):\n",
    "    def __init__(self, num_pieces, name='AMU',**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.__name__ = name\n",
    "        self.num_pieces = num_pieces\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, x, axis=None):\n",
    "        shape = x.get_shape().as_list()\n",
    "        if axis is None:\n",
    "            axis = -1\n",
    "            shape[0] = -1\n",
    "        if shape[axis]%2:\n",
    "            raise ValueError(f'nb of real/imaginary channel are inequivalent')\n",
    "        num_channels = shape[-1]//2\n",
    "        self.num_units = num_channels//self.num_pieces\n",
    "        if num_channels%self.num_pieces:\n",
    "            self.num_units += 1\n",
    "            num_padding = self.num_pieces - num_channels%self.num_pieces\n",
    "            padding_size = tf.concat([tf.shape(x)[:-1],tf.constant([num_padding])],axis=-1)\n",
    "            zero_padding = tf.zeros(padding_size)           \n",
    "        shape[axis] = self.num_units\n",
    "        exp_shape = shape + [self.num_pieces]\n",
    "        real_part = x[:,:,:,:num_channels]\n",
    "        imag_part = x[:,:,:,num_channels:]        \n",
    "        if num_channels%self.num_pieces:\n",
    "            real_part = tf.concat([real_part,zero_padding], axis=-1)\n",
    "            imag_part = tf.concat([imag_part,zero_padding], axis=-1)\n",
    "        real_part = tf.reshape(real_part, exp_shape)\n",
    "        imag_part = tf.reshape(real_part, exp_shape)\n",
    "        real_part, imag_part = self.return_AMU(real_part, imag_part, exp_shape)\n",
    "        return tf.concat([real_part,imag_part],axis=-1)         \n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        shape = list(input_shape)\n",
    "        shape[-1] = 2*self.num_units\n",
    "        return tuple(shape)\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        config = {'units': self.num_units,\n",
    "                  'pieces': self.num_pieces}\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "    \n",
    "    def return_AMU(self, real_part, imag_part ,expand_shape):\n",
    "        modulus = real_part**2 + imag_part**2\n",
    "        expand_modulus = tf.reshape(modulus, expand_shape)    \n",
    "        cond = tf.equal(expand_modulus,tf.reduce_max(expand_modulus,axis=-1,keepdims=True))\n",
    "        real_part = tf.reduce_max(real_part*tf.cast(cond,dtype=tf.float32),axis=-1)\n",
    "        imag_part = tf.reduce_max(imag_part*tf.cast(cond,dtype=tf.float32),axis=-1)\n",
    "        return real_part, imag_part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4131c24f",
   "metadata": {},
   "source": [
    "# Loss function: MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0023cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def ComplexRMS(y_true, y_pred):\n",
    "    shape = y_pred.get_shape().as_list()\n",
    "    if shape[-1]%2:\n",
    "        raise ValueError(f\"nb of imaginary part isn't equal to that of real part\")\n",
    "    num_channels = shape[-1]//2\n",
    "    n_points = 1\n",
    "    for n in shape[1:]:\n",
    "        n_points = n_points*n\n",
    "    n_points = tf.cast(n_points,dtype=tf.float32)/2\n",
    "    real_pdt = y_pred[:,:,:,num_channels:]\n",
    "    imag_pdt = y_pred[:,:,:,:num_channels]\n",
    "    real_true = y_true[:,:,:,num_channels:]\n",
    "    imag_true = y_true[:,:,:,:num_channels]\n",
    "    return tf.sqrt(tf.reduce_sum((real_pdt-real_true)**2+(imag_pdt-imag_true)**2)/n_points)\n",
    "@tf.function\n",
    "def ComplexMSE(y_true, y_pred):\n",
    "    shape = y_pred.get_shape().as_list()\n",
    "    if shape[-1]%2:\n",
    "        raise ValueError(f\"nb of imaginary part isn't equal to that of real part\")\n",
    "    num_channels = shape[-1]//2\n",
    "    n_points = 1\n",
    "    for n in shape[1:]:\n",
    "        n_points = n_points*n\n",
    "    n_points = tf.cast(n_points,dtype=tf.float32)/2\n",
    "    real_pdt = y_pred[:,:,:,num_channels:]\n",
    "    imag_pdt = y_pred[:,:,:,:num_channels]\n",
    "    real_true = y_true[:,:,:,num_channels:]\n",
    "    imag_true = y_true[:,:,:,:num_channels]\n",
    "    return tf.reduce_sum(((real_pdt-real_true)**2+(imag_pdt-imag_true)**2)) / n_points\n",
    "@tf.function\n",
    "def ComplexMAE(y_true, y_pred):\n",
    "    shape = y_pred.get_shape().as_list()\n",
    "    if shape[-1]%2:\n",
    "        raise ValueError(f\"nb of imaginary part isn't equal to that of real part\")\n",
    "    num_channels = shape[-1]//2\n",
    "    n_points = 1\n",
    "    for n in shape[1:]:\n",
    "        n_points = n_points*n\n",
    "    n_points = tf.cast(n_points,dtype=tf.float32)/2\n",
    "    real_pdt = y_pred[:,:,:,num_channels:]\n",
    "    imag_pdt = y_pred[:,:,:,:num_channels]\n",
    "    real_true = y_true[:,:,:,num_channels:]\n",
    "    imag_true = y_true[:,:,:,:num_channels]\n",
    "    return tf.reduce_sum(tf.sqrt((real_pdt-real_true)**2+(imag_pdt-imag_true)**2)) / n_points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5a8d009",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[4.17022005e-01 7.20324493e-01 1.14374817e-04 3.02332573e-01]\n",
      "   [1.46755891e-01 9.23385948e-02 1.86260211e-01 3.45560727e-01]\n",
      "   [3.96767474e-01 5.38816734e-01 4.19194514e-01 6.85219500e-01]\n",
      "   [2.04452250e-01 8.78117436e-01 2.73875932e-02 6.70467510e-01]\n",
      "   [4.17304802e-01 5.58689828e-01 1.40386939e-01 1.98101489e-01]\n",
      "   [8.00744569e-01 9.68261576e-01 3.13424178e-01 6.92322616e-01]\n",
      "   [8.76389152e-01 8.94606664e-01 8.50442114e-02 3.90547832e-02]]\n",
      "\n",
      "  [[1.69830420e-01 8.78142503e-01 9.83468338e-02 4.21107625e-01]\n",
      "   [9.57889530e-01 5.33165285e-01 6.91877114e-01 3.15515631e-01]\n",
      "   [6.86500928e-01 8.34625672e-01 1.82882773e-02 7.50144315e-01]\n",
      "   [9.88861089e-01 7.48165654e-01 2.80443992e-01 7.89279328e-01]\n",
      "   [1.03226007e-01 4.47893526e-01 9.08595503e-01 2.93614148e-01]\n",
      "   [2.87775339e-01 1.30028572e-01 1.93669579e-02 6.78835533e-01]\n",
      "   [2.11628116e-01 2.65546659e-01 4.91573159e-01 5.33625451e-02]]\n",
      "\n",
      "  [[5.74117605e-01 1.46728575e-01 5.89305537e-01 6.99758360e-01]\n",
      "   [1.02334429e-01 4.14055988e-01 6.94400158e-01 4.14179270e-01]\n",
      "   [4.99534589e-02 5.35896406e-01 6.63794645e-01 5.14889112e-01]\n",
      "   [9.44594756e-01 5.86555041e-01 9.03401915e-01 1.37474704e-01]\n",
      "   [1.39276347e-01 8.07391289e-01 3.97676837e-01 1.65354197e-01]\n",
      "   [9.27508580e-01 3.47765860e-01 7.50812103e-01 7.25997985e-01]\n",
      "   [8.83306091e-01 6.23672207e-01 7.50942434e-01 3.48898342e-01]]\n",
      "\n",
      "  [[2.69927892e-01 8.95886218e-01 4.28091190e-01 9.64840047e-01]\n",
      "   [6.63441498e-01 6.21695720e-01 1.14745973e-01 9.49489259e-01]\n",
      "   [4.49912133e-01 5.78389614e-01 4.08136803e-01 2.37026980e-01]\n",
      "   [9.03379521e-01 5.73679487e-01 2.87032703e-03 6.17144914e-01]\n",
      "   [3.26644902e-01 5.27058102e-01 8.85942099e-01 3.57269760e-01]\n",
      "   [9.08535151e-01 6.23360116e-01 1.58212428e-02 9.29437234e-01]\n",
      "   [6.90896918e-01 9.97322850e-01 1.72340508e-01 1.37135750e-01]]\n",
      "\n",
      "  [[9.32595463e-01 6.96818161e-01 6.60001727e-02 7.55463053e-01]\n",
      "   [7.53876188e-01 9.23024536e-01 7.11524759e-01 1.24270962e-01]\n",
      "   [1.98801338e-02 2.62109869e-02 2.83064880e-02 2.46211068e-01]\n",
      "   [8.60027949e-01 5.38831064e-01 5.52821979e-01 8.42030892e-01]\n",
      "   [1.24173315e-01 2.79183679e-01 5.85759271e-01 9.69595748e-01]\n",
      "   [5.61030219e-01 1.86472894e-02 8.00632673e-01 2.32974274e-01]\n",
      "   [8.07105196e-01 3.87860644e-01 8.63541855e-01 7.47121643e-01]]\n",
      "\n",
      "  [[5.56240234e-01 1.36455226e-01 5.99176895e-02 1.21343456e-01]\n",
      "   [4.45518785e-02 1.07494129e-01 2.25709339e-01 7.12988980e-01]\n",
      "   [5.59716982e-01 1.25559802e-02 7.19742797e-02 9.67276330e-01]\n",
      "   [5.68100462e-01 2.03293235e-01 2.52325745e-01 7.43825854e-01]\n",
      "   [1.95429481e-01 5.81358927e-01 9.70019989e-01 8.46828801e-01]\n",
      "   [2.39847759e-01 4.93769714e-01 6.19955718e-01 8.28980900e-01]\n",
      "   [1.56791395e-01 1.85762022e-02 7.00221437e-02 4.86345111e-01]]\n",
      "\n",
      "  [[6.06329462e-01 5.68851437e-01 3.17362409e-01 9.88616154e-01]\n",
      "   [5.79745219e-01 3.80141173e-01 5.50948219e-01 7.45334431e-01]\n",
      "   [6.69232893e-01 2.64919558e-01 6.63348344e-02 3.70084198e-01]\n",
      "   [6.29717507e-01 2.10174010e-01 7.52755554e-01 6.65364814e-02]\n",
      "   [2.60315099e-01 8.04754564e-01 1.93434283e-01 6.39460881e-01]\n",
      "   [5.24670309e-01 9.24807970e-01 2.63296770e-01 6.59610907e-02]\n",
      "   [7.35065963e-01 7.72178030e-01 9.07815853e-01 9.31972069e-01]]]]\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "x_train = np.random.rand(61,64,64,32)\n",
    "y_train = np.random.rand(61,64,64,2)\n",
    "input_size = x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f702441",
   "metadata": {},
   "source": [
    "使用上keras會檢查層與層之間的input_shape與output_shape，若我們將activation放在ComplexConv2D中輸出的channel數會減少，e.g. 設定16 filters輸出32 channel但經過AMU(4)後會剩下8 channels，若下層再增加Conv layer則會跳出輸出channel數8不是32倍數的錯誤資訊，因此受限於AMU只能設定輸出和Conv同輸出# channel，要解決這個問題需要將activation獨立出成一個layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "585357d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "complex_conv2d_1 (ComplexCon (None, 7, 7, 32)          608       \n",
      "_________________________________________________________________\n",
      "amplitude_maxout_1 (Amplitud (None, 7, 7, 8)           0         \n",
      "_________________________________________________________________\n",
      "incept_layer_1 (InceptLayer) (None, 7, 7, 8)           1760      \n",
      "_________________________________________________________________\n",
      "complex_conv2d_6 (ComplexCon (None, 7, 7, 2)           10        \n",
      "=================================================================\n",
      "Total params: 2,378\n",
      "Trainable params: 2,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[[[[ 0.00412539  0.0016796 ]\n",
      "   [ 0.00480253 -0.0018454 ]\n",
      "   [ 0.02798994  0.02553133]\n",
      "   [ 0.0409994   0.02085593]\n",
      "   [ 0.03826549 -0.00754606]\n",
      "   [ 0.01735482  0.015537  ]\n",
      "   [-0.00400526 -0.00087712]]\n",
      "\n",
      "  [[ 0.00114611 -0.01676142]\n",
      "   [-0.0027918  -0.01188334]\n",
      "   [ 0.03600683 -0.00663509]\n",
      "   [ 0.02761663  0.01403645]\n",
      "   [ 0.07657168  0.01815258]\n",
      "   [ 0.06115686  0.01084954]\n",
      "   [ 0.02267038  0.01659096]]\n",
      "\n",
      "  [[-0.00584984  0.03853605]\n",
      "   [ 0.04082636  0.0287895 ]\n",
      "   [ 0.00912945  0.00870567]\n",
      "   [ 0.03642198  0.04864936]\n",
      "   [ 0.05602849  0.02328046]\n",
      "   [-0.00110885  0.04893864]\n",
      "   [ 0.03355272  0.01044752]]\n",
      "\n",
      "  [[ 0.02303882  0.00678732]\n",
      "   [ 0.00532208  0.01646964]\n",
      "   [ 0.14368819  0.01072748]\n",
      "   [ 0.02890832  0.04654982]\n",
      "   [ 0.08642635  0.01019745]\n",
      "   [ 0.05949792  0.03139615]\n",
      "   [-0.04434184  0.01902047]]\n",
      "\n",
      "  [[ 0.0307571   0.01407482]\n",
      "   [ 0.04641647  0.01732413]\n",
      "   [ 0.05225309  0.00568411]\n",
      "   [ 0.01597434  0.0429701 ]\n",
      "   [ 0.06065421  0.01555814]\n",
      "   [ 0.02331317 -0.0015181 ]\n",
      "   [ 0.06142232  0.01765678]]\n",
      "\n",
      "  [[-0.00754628 -0.0120829 ]\n",
      "   [-0.00237185  0.03220055]\n",
      "   [ 0.02738051  0.02751096]\n",
      "   [ 0.06033875  0.00573019]\n",
      "   [ 0.03294706  0.01534823]\n",
      "   [ 0.08328793  0.00958624]\n",
      "   [ 0.03545969  0.0501428 ]]\n",
      "\n",
      "  [[ 0.00402533 -0.00095516]\n",
      "   [-0.02873738  0.01426166]\n",
      "   [ 0.03996967 -0.00898238]\n",
      "   [ 0.03218589  0.00091754]\n",
      "   [ 0.04844245  0.00100589]\n",
      "   [ 0.07975751  0.00324642]\n",
      "   [ 0.00648118  0.04688231]]]]\n"
     ]
    }
   ],
   "source": [
    "InputTensor = keras.Input(shape=input_shapes)\n",
    "conv1 = complexnn.conv.ComplexConv2D(64,(3,3),padding='same')(InputTensor)\n",
    "amp1 = AmplitudeMaxout_inclued(4)(conv1)\n",
    "conv2 = complexnn.conv.ComplexConv2D(16,(3,3),padding='same')(amp1)\n",
    "amp2 = AmplitudeMaxout_inclued(4)(conv2)\n",
    "incep = InceptLayer(filter1=4,\n",
    "                    filter2=4,\n",
    "                    filter3=4,\n",
    "                    filter4=4,\n",
    "                    kernel1=(3,5),\n",
    "                    kernel2=(3,3),\n",
    "                    kernel3=(5,3),\n",
    "                    kernel4=(3,5),\n",
    "                    num_units=4)(amp2)\n",
    "Output = complexnn.conv.ComplexConv2D(1,(1,1),padding='same')(incep)\n",
    "\n",
    "model = keras.Model(inputs=InputTensor,outputs=Output)\n",
    "model.built\n",
    "model.summary()\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),loss=ComplexMSE)\n",
    "model.fit(x_train,y_train,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c635a192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_conv_tf(x,w,b):\n",
    "    x_shape = list(x.shape)\n",
    "    x_dim = x_shape[-1]//2\n",
    "    xre = x[:,:,:,:x_dim]\n",
    "    xim = x[:,:,:,x_dim:]\n",
    "    \n",
    "    w_shape = list(w.shape)\n",
    "    w_dim = w_shape[-1]//2\n",
    "    new_shape = [w_shape[0],w_shape[1],x_dim,w_dim]\n",
    "    wre = w[:,:,:,:w_dim].reshape(new_shape)\n",
    "    wim = w[:,:,:,w_dim:].reshape(new_shape)\n",
    "    crr = tf.nn.conv2d(xre, wre, strides=1, padding='SAME')\n",
    "    cii = tf.nn.conv2d(xim, wim, strides=1, padding='SAME')\n",
    "    cri = tf.nn.conv2d(xre, wim, strides=1, padding='SAME')\n",
    "    cir = tf.nn.conv2d(xim, wre, strides=1, padding='SAME')\n",
    "    return tf.nn.bias_add(np.concatenate([crr-cii,cri+cir],axis=-1),b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a90318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_conv_keras(x,w,b):\n",
    "    x_shape = list(x.shape)\n",
    "    x_dim = x_shape[-1]//2\n",
    "    xre = x[:,:,:,:x_dim]\n",
    "    xim = x[:,:,:,x_dim:]\n",
    "    \n",
    "    w_shape = list(w.shape)\n",
    "    w_dim = w_shape[-1]//2\n",
    "    new_shape = [w_shape[0],w_shape[1],x_dim,w_dim]\n",
    "    wre = w[:,:,:,:w_dim].reshape(new_shape)\n",
    "    wim = w[:,:,:,w_dim:].reshape(new_shape)\n",
    "    \n",
    "    xre = tf.convert_to_tensor(xre,dtype=tf.float32)\n",
    "    xim = tf.convert_to_tensor(xim,dtype=tf.float32)\n",
    "    crr = tf.keras.backend.conv2d(xre, wre, strides=1, padding='same')\n",
    "\n",
    "    cii = tf.keras.backend.conv2d(xim, wim, strides=1, padding='same')\n",
    "\n",
    "    cri = tf.keras.backend.conv2d(xre, wim, strides=1, padding='same')\n",
    "\n",
    "    cir = tf.keras.backend.conv2d(xim, wre, strides=1, padding='same')\n",
    "    return tf.nn.bias_add(np.concatenate([crr-cii,cri+cir],axis=-1),b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b778b435",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_conv1,b_conv1,w_incept1,b_incept1,w_incept2,b_incept2,w_incept3,b_incept3,w_incept4,b_incept4,w_conv2,b_conv2 = model.weights\n",
    "print('conv1 result: /n')\n",
    "print(testconv(x_train,w_conv1,b_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1b5266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Complex)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
